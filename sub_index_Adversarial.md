## 对抗样本

|                            label                             |                            remark                            |
| :----------------------------------------------------------: | :----------------------------------------------------------: |
| [对抗样本生成算法](./docs/Adversarial/Adversarial_example.md) |                    常见的对抗样本生成算法                    |
|               [PGD](./docs/Adversarial/PGD.md)               | [Reliable Evaluation of Adversarial Robustness with an Ensemble of Diverse Parameter-free Attacks](https://arxiv.org/abs/2003.01690) |
| [FGSM](./docs/Adversarial/EXPLAINING_AND_HARNESSING_ADVERSARIAL_EXAMPLES.md) | [EXPLAINING AND HARNESSING ADVERSARIAL EXAMPLES](https://arxiv.org/abs/1412.6572) |
| [LLM Self Denfense](./docs/Adversarial/LLM_Self_Defense.md)  | LLM Self Defense: By Self Examination, LLMs Know They Are Being Tricked |
|                    [LLM(universal atk)](./docs/Adversarial/AdvAtk_on_ALM.md)                    | Universal and Transferable Adversarial Attacks on Aligned Language Models |
|||